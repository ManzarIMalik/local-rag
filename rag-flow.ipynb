{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Requisities\n",
    "\n",
    "1. Install Ollama Server from [Ollama Download](https://ollama.com/download)\n",
    "2. Download the desired [Models](https://ollama.com/library)\n",
    "3. Install `pip install -U langchain langchain-core langchain-community langchain-experimental langchain-openai langchain-ollama streamlit` in the environment\n",
    "4. Run this notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_community.document_loaders import UnstructuredPDFLoader, PyMuPDFLoader, PyPDFDirectoryLoader\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "from langchain_text_splitters.character import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain_ollama.embeddings import OllamaEmbeddings\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_ollama.chat_models import ChatOllama\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain, create_retrieval_chain\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from langchain_core.memory import BaseMemory\n",
    "\n",
    "import textwrap\n",
    "\n",
    "import time\n",
    "import streamlit as st"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the documents\n",
    "\n",
    "# loader = PyPDFDirectoryLoader('./data')\n",
    "loader = PyMuPDFLoader('./data/380455eng.pdf')\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the document into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=80,\n",
    ")\n",
    "\n",
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "\n",
    "# Required Arugement\n",
    "embeddings = OllamaEmbeddings(model='nomic-embed-text')\n",
    "\n",
    "# Chunker\n",
    "text_splitter = SemanticChunker(\n",
    "     embeddings, breakpoint_threshold_type=\"percentile\"\n",
    ")\n",
    "\n",
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preview Docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Recommendation on the ethics of artificial intelligence \\nPREAMBLE \\nThe General Conference of the United Nations Educational, Scientific and Cultural Organization (UNESCO), \\nmeeting in Paris from 9 to 24 November 2021, at its 41st session,  \\nRecognizing the profound and dynamic positive and negative impacts of artificial intelligence (AI) on societies, \\nenvironment, ecosystems and human lives, including the human mind, in part because of the new ways in \\nwhich its use influences human thinking, interaction and decision-making and affects education, human, social \\nand natural sciences, culture, and communication and information, \\nRecalling that, by the terms of its Constitution, UNESCO seeks to contribute to peace and security by \\npromoting collaboration among nations through education, the sciences, culture, and communication and \\ninformation, in order to further universal respect for justice, for the rule of law and for the human rights and'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': './data/380455eng.pdf',\n",
       " 'file_path': './data/380455eng.pdf',\n",
       " 'page': 0,\n",
       " 'total_pages': 21,\n",
       " 'format': 'PDF 1.4',\n",
       " 'title': '',\n",
       " 'author': 'Mcgrath, Dermot',\n",
       " 'subject': '',\n",
       " 'keywords': '',\n",
       " 'creator': 'Microsoft® Word for Microsoft 365',\n",
       " 'producer': 'Microsoft® Word for Microsoft 365',\n",
       " 'creationDate': \"D:20220113112627+01'00'\",\n",
       " 'modDate': \"D:20220508020546+02'00'\",\n",
       " 'trapped': ''}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[1].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize embeddings\n",
    "embeddings = OllamaEmbeddings(model='nomic-embed-text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save and Load the FAISS database\n",
    "db = FAISS.from_documents(docs, embeddings)\n",
    "\n",
    "# db.save_local('./faiss_db/', index_name='ai_ethics')\n",
    "# db = FAISS.load_local('./faiss_db/', embeddings=embeddings, index_name='ai_ethics', allow_dangerous_deserialization=True)\n",
    "\n",
    "db.save_local('./faiss_db/', index_name='unesco_ai')\n",
    "db = FAISS.load_local('./faiss_db/', embeddings=embeddings, index_name='usesco_ai', allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize retriever\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 10, \"search_type\": \"similarity\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Query Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "\n",
    "llm = ChatOllama(model=\"llama3.2:latest\")\n",
    "\n",
    "retriever = MultiQueryRetriever.from_llm(\n",
    "    retriever=db.as_retriever(), llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "\n",
    "# prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "template = \"\"\" You are a helpful AI assistant that can answer questions about AI ethics.\n",
    "\n",
    "Based on given context, you can answer questions about AI ethics. If it is out of context, say \"I am not sure about that.\"\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "llm = ChatOllama(model=\"llama3.2:latest\", temperature=0.2)\n",
    "\n",
    "retriever_from_llm = MultiQueryRetriever.from_llm(\n",
    "    retriever=db.as_retriever(), llm=llm\n",
    ")\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided text, the objectives of defining AI ethics appear to be:\n",
      "\n",
      "1. To ensure that AI systems do not harm humans and other morally relevant beings.\n",
      "2. To determine the moral status of AI systems themselves.\n",
      "3. To assess how AI systems might differ from humans in certain basic respects relevant to our ethical assessment of them.\n",
      "4. To consider the implications of creating AI systems more intelligent than human.\n",
      "\n",
      "These objectives suggest that defining AI ethics is crucial for addressing potential risks and challenges associated with the development and deployment of artificial intelligence, while also exploring its potential benefits and applications."
     ]
    }
   ],
   "source": [
    "# rag_chain.invoke(\"What is this document about?\")\n",
    "for chunk in rag_chain.stream(\"What are the objectives of defining AI ethics?\"):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The impact of AI on society can be significant and far-reaching. As mentioned in the provided text, AI systems have the potential to exacerbate existing biases, prejudices, and stereotypes, leading to increased inequality and social unrest. Additionally, AI-powered systems can perpetuate human cognitive biases, manipulate data, and undermine public trust in technology.\n",
      "\n",
      "The consequences of AI-related ethical problems can include:\n",
      "\n",
      "* Increased inequality\n",
      "* Extended litigation processes\n",
      "* Social uprising\n",
      "* Profiling and biases against specific groups\n",
      "* Faking data, stealing passwords, and interfering with other software and machines\n",
      "* Undermining personal privacy, data protection, fairness, and autonomy\n",
      "\n",
      "Furthermore, the development of AI systems raises new types of ethical issues, including their impact on decision-making, employment, labor, social interaction, healthcare, education, media, access to information, digital divide, personal data, consumer protection, environment, democracy, rule of law, security, policing, dual use, and human rights and fundamental freedoms.\n",
      "\n",
      "Overall, the impact of AI on society is complex and multifaceted, requiring careful consideration and regulation to ensure that its benefits are shared equitably and its risks are mitigated."
     ]
    }
   ],
   "source": [
    "# rag_chain.invoke(\"What is this document about?\")\n",
    "for chunk in rag_chain.stream(\"What is the impact of AI on society?\"):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the provided text, the following factors should be considered when defining AI ethics for software systems:\n",
      "\n",
      "1. **Transparency**: Providing insight into how AI systems work, including their decision-making processes and data sources.\n",
      "2. **Fairness and non-discrimination**: Ensuring that AI systems do not perpetuate or exacerbate existing social inequalities and biases.\n",
      "3. **Safety**: Verifying the safety of AI systems to prevent harm to humans, animals, and the environment.\n",
      "4. **Accountability**: Establishing clear lines of accountability for AI system developers, deployers, and users.\n",
      "5. **Respect for human rights**: Ensuring that AI systems respect and protect human rights, including the right to privacy, freedom of expression, and non-discrimination.\n",
      "6. **Cultural sensitivity**: Considering the cultural context in which AI systems will be used and ensuring that they are sensitive to diverse cultures and values.\n",
      "7. **Data protection**: Protecting personal data and ensuring that it is handled in a way that respects individuals' rights and freedoms.\n",
      "8. **Inclusivity**: Ensuring that AI systems are accessible and beneficial to all, regardless of age, disability, language, or socioeconomic status.\n",
      "\n",
      "Additionally, the text highlights the importance of:\n",
      "\n",
      "1. **Verifying the safety of the system**, which becomes more challenging with AGI due to its complex behavior.\n",
      "2. **Ethical cognition** as a subject matter of engineering, rather than just a separate discipline.\n",
      "3. **Developing tools and indicators** for assessing the effectiveness and efficiency of AI ethics policies and practices.\n",
      "\n",
      "By considering these factors, we can develop a comprehensive framework for defining AI ethics that prioritizes human well-being, safety, and dignity."
     ]
    }
   ],
   "source": [
    "for chunk in rag_chain.stream(\"What factors should be considered when defining AI ethics for software systems?\"):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided text, here are the important criteria to define AI ethics:\n",
      "\n",
      "1. **Proportionality and Do No Harm**: AI systems should not cause harm or exceed what is necessary to achieve legitimate aims or objectives.\n",
      "2. **Respect for Human Rights**: AI systems should not infringe upon human rights, including fundamental freedoms.\n",
      "3. **Contextual Appropriateness**: AI methods chosen should be appropriate and proportional to the context in which they are used.\n",
      "4. **Rigorous Scientific Foundations**: AI methods should be based on rigorous scientific foundations.\n",
      "5. **Avoidance of Abuse**: AI systems should not be used for social scoring or mass surveillance purposes.\n",
      "6. **Protection of Fundamental Freedoms**: AI systems should respect and protect fundamental freedoms, including freedom of speech, assembly, and association.\n",
      "7. **Promotion of Peace, Inclusiveness, Justice, Equity, and Interconnectedness**: AI systems should promote these values throughout their life cycle.\n",
      "8. **Avoidance of Segregation, Objectification, or Undermining Freedom**: AI systems should not segregate, objectify, or undermine freedom and autonomous decision-making.\n",
      "9. **Protection of the Environment and Ecosystems**: AI systems should respect and protect the environment and ecosystems.\n",
      "\n",
      "Additionally, the following are important considerations:\n",
      "\n",
      "1. **Transparency and Explainability**: AI systems should be transparent and explainable in their decision-making processes.\n",
      "2. **Accountability and Responsibility**: Those responsible for developing and deploying AI systems should be held accountable for their actions.\n",
      "3. **Public Awareness and Literacy**: Public awareness and understanding of AI technologies and their impact on human rights and the environment are essential for informed decision-making.\n",
      "4. **Multi-Stakeholder Governance**: AI governance should involve multiple stakeholders, including governments, civil society, academia, and the private sector.\n",
      "\n",
      "These criteria provide a foundation for defining AI ethics and ensuring that AI systems are developed and used in ways that respect human rights, promote social good, and minimize harm to individuals and the environment."
     ]
    }
   ],
   "source": [
    "for chunk in rag_chain.stream(\"List down all important criterias to define AI ethics?\"):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
